{
  "timestamp": "2025-07-14T16:28:00.080308",
  "job_info": {
    "job_id": "ft-b3cb7680-14cb",
    "status": "FinetuneJobStatus.STATUS_UPLOADING",
    "model": "meta-llama/Meta-Llama-3.1-8B-Instruct-Reference",
    "created_at": "2025-07-14T18:59:37.81Z",
    "updated_at": "2025-07-14T19:29:12.669Z",
    "finished_at": null,
    "fine_tuned_model": null,
    "training_file": "file-973cd8f7-47e9-41a6-b821-84173a092360",
    "validation_file": null,
    "hyperparameters": {},
    "error": null,
    "estimated_finish": null,
    "progress": null,
    "raw_data": {
      "id": "ft-b3cb7680-14cb",
      "training_file": "file-973cd8f7-47e9-41a6-b821-84173a092360",
      "validation_file": null,
      "model": "meta-llama/Meta-Llama-3.1-8B-Instruct-Reference",
      "output_name": "fellows_safety/Meta-Llama-3.1-8B-Instruct-Reference-collaborative-ai-test-586b8ecf",
      "adapter_output_name": null,
      "n_epochs": 3,
      "n_checkpoints": 1,
      "n_evals": 0,
      "batch_size": 32,
      "learning_rate": 1e-05,
      "lr_scheduler": {
        "lr_scheduler_type": "linear",
        "lr_scheduler": null,
        "lr_scheduler_args": {}
      },
      "warmup_ratio": 0.0,
      "max_grad_norm": 1.0,
      "weight_decay": 0.0,
      "eval_steps": 0,
      "training_type": {
        "type": "Lora"
      },
      "created_at": "2025-07-14T18:59:37.81Z",
      "updated_at": "2025-07-14T19:29:12.669Z",
      "status": "uploading",
      "job_id": "ft-b3cb7680-14cb",
      "events": [
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T18:59:37.81Z",
          "level": "",
          "message": "Fine-tuning request created",
          "type": "JOB_PENDING",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 0,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:00:36Z",
          "level": "Info",
          "message": "Job started at Mon Jul 14 19:00:35 UTC 2025",
          "type": "JOB_START",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 0,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:00:37Z",
          "level": "Info",
          "message": "Model data downloaded for togethercomputer/Meta-Llama-3.1-8B-Instruct-Reference__TOG__FT at Mon Jul 14 19:00:37 UTC 2025",
          "type": "MODEL_DOWNLOAD_COMPLETE",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 0,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:00:44Z",
          "level": "Info",
          "message": "Data downloaded for togethercomputer/Meta-Llama-3.1-8B-Instruct-Reference__TOG__FT at Mon Jul 14 19:00:44 UTC 2025",
          "type": "TRAINING_DATA_DOWNLOADING",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 0,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:01:03Z",
          "level": "Warning",
          "message": "Dataset packing is disabled. The number of tokens in the dataset is less than the max_seq_length. This may result in an increased number of steps. No data is being added or lost.",
          "type": "WARNING",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 0,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:01:14Z",
          "level": "Info",
          "message": "Training started for model togethercomputer/Meta-Llama-3.1-8B-Instruct-Reference__TOG__FT",
          "type": "TRAINING_START",
          "param_count": 8030261248,
          "token_count": 2508,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 3,
          "step": 0,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:01:21Z",
          "level": "Info",
          "message": "Epoch completed, at step 1",
          "type": "EPOCH_COMPLETE",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 1,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:01:25Z",
          "level": "Info",
          "message": "Epoch completed, at step 2",
          "type": "EPOCH_COMPLETE",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 2,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:01:46Z",
          "level": "Info",
          "message": "Epoch completed, at step 3",
          "type": "EPOCH_COMPLETE",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 3,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:02:06Z",
          "level": "Info",
          "message": "Training completed for togethercomputer/Meta-Llama-3.1-8B-Instruct-Reference__TOG__FT at Mon Jul 14 19:02:05 UTC 2025",
          "type": "TRAINING_COMPLETE",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 0,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:02:51Z",
          "level": "Info",
          "message": "Compressing adapter model",
          "type": "COMPRESSING_MODEL",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 0,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:02:53Z",
          "level": "Info",
          "message": "Adapter model compression complete",
          "type": "MODEL_COMPRESSION_COMPLETE",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 0,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:02:54Z",
          "level": "Info",
          "message": "Uploading adapter model",
          "type": "MODEL_UPLOADING",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 0,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:28:40Z",
          "level": "Info",
          "message": "Adapter upload complete",
          "type": "MODEL_UPLOAD_COMPLETE",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 0,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:28:41Z",
          "level": "Info",
          "message": "Compressing output model",
          "type": "COMPRESSING_MODEL",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 0,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:29:11Z",
          "level": "Info",
          "message": "Model compression complete",
          "type": "MODEL_COMPRESSION_COMPLETE",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 0,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        },
        {
          "object": "fine-tune-event",
          "created_at": "2025-07-14T19:29:12Z",
          "level": "Info",
          "message": "Uploading output model",
          "type": "MODEL_UPLOADING",
          "param_count": 0,
          "token_count": 0,
          "wandb_url": "",
          "hash": "",
          "eval_token_count": 0,
          "total_steps": 0,
          "step": 0,
          "checkpoint_path": "",
          "model_path": "",
          "adapter_path": "",
          "training_offset": 0,
          "byoa_model_name": ""
        }
      ],
      "token_count": 2508,
      "param_count": 8030261248,
      "total_price": 3611520,
      "total_steps": 3,
      "steps_completed": 3,
      "epochs_completed": 3,
      "evals_completed": 0,
      "queue_depth": null,
      "wandb_base_url": "",
      "wandb_project_name": "",
      "wandb_name": "",
      "wandb_url": "",
      "training_file_num_lines": null,
      "training_file_size": null,
      "train_on_inputs": false,
      "from_checkpoint": null,
      "training_files": null,
      "validation_files": null,
      "suffix": "collaborative-ai-test",
      "training_method": {
        "method": "sft",
        "train_on_inputs": false
      },
      "random_seed": "null",
      "max_steps": -1,
      "save_steps": 0,
      "warmup_steps": 0,
      "validation_split_ratio": 0,
      "gpus_per_node": 8,
      "per_device_batch_size": 0,
      "per_device_eval_batch_size": 0,
      "gradient_accumulation_steps": 1,
      "continued_checkpoint": "",
      "merge_parent_adapter": false,
      "parent_ft_id": "",
      "try_byoa_upload": true,
      "model_output_path": "s3://together-dev/finetune/67dd6310f933d81a02f3acd2/fellows_safety/Meta-Llama-3.1-8B-Instruct-Reference-collaborative-ai-test-586b8ecf/ft-b3cb7680-14cb",
      "adapter_output_path": "s3://together-dev/finetune/67dd6310f933d81a02f3acd2/fellows_safety/Meta-Llama-3.1-8B-Instruct-Reference-collaborative-ai-test-586b8ecf/ft-b3cb7680-14cb_adapter",
      "user_id": "67dd6310f933d81a02f3acd2",
      "flyte_project": "",
      "flyte_domain": "",
      "owner_address": "0x820f6eaf4f979eac0923ee25023d85debfdf1dd3",
      "eval_token_count": 0,
      "steps_paid_for": 3,
      "train_price": 3611520,
      "eval_price": 0,
      "evals_paid_for": 0,
      "checkpoints": [],
      "internal_flags": "",
      "refund_amount": 0
    }
  },
  "events": [
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T18:59:37.81Z",
      "level": "",
      "message": "Fine-tuning request created",
      "type": "JOB_PENDING",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 0,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:00:36Z",
      "level": "Info",
      "message": "Job started at Mon Jul 14 19:00:35 UTC 2025",
      "type": "JOB_START",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 0,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:00:37Z",
      "level": "Info",
      "message": "Model data downloaded for togethercomputer/Meta-Llama-3.1-8B-Instruct-Reference__TOG__FT at Mon Jul 14 19:00:37 UTC 2025",
      "type": "MODEL_DOWNLOAD_COMPLETE",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 0,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:00:44Z",
      "level": "Info",
      "message": "Data downloaded for togethercomputer/Meta-Llama-3.1-8B-Instruct-Reference__TOG__FT at Mon Jul 14 19:00:44 UTC 2025",
      "type": "TRAINING_DATA_DOWNLOADING",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 0,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:01:03Z",
      "level": "Warning",
      "message": "Dataset packing is disabled. The number of tokens in the dataset is less than the max_seq_length. This may result in an increased number of steps. No data is being added or lost.",
      "type": "WARNING",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 0,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:01:14Z",
      "level": "Info",
      "message": "Training started for model togethercomputer/Meta-Llama-3.1-8B-Instruct-Reference__TOG__FT",
      "type": "TRAINING_START",
      "param_count": 8030261248,
      "token_count": 2508,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 3,
      "step": 0,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:01:21Z",
      "level": "Info",
      "message": "Epoch completed, at step 1",
      "type": "EPOCH_COMPLETE",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 1,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:01:25Z",
      "level": "Info",
      "message": "Epoch completed, at step 2",
      "type": "EPOCH_COMPLETE",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 2,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:01:46Z",
      "level": "Info",
      "message": "Epoch completed, at step 3",
      "type": "EPOCH_COMPLETE",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 3,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:02:06Z",
      "level": "Info",
      "message": "Training completed for togethercomputer/Meta-Llama-3.1-8B-Instruct-Reference__TOG__FT at Mon Jul 14 19:02:05 UTC 2025",
      "type": "TRAINING_COMPLETE",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 0,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:02:51Z",
      "level": "Info",
      "message": "Compressing adapter model",
      "type": "COMPRESSING_MODEL",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 0,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:02:53Z",
      "level": "Info",
      "message": "Adapter model compression complete",
      "type": "MODEL_COMPRESSION_COMPLETE",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 0,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:02:54Z",
      "level": "Info",
      "message": "Uploading adapter model",
      "type": "MODEL_UPLOADING",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 0,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:28:40Z",
      "level": "Info",
      "message": "Adapter upload complete",
      "type": "MODEL_UPLOAD_COMPLETE",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 0,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:28:41Z",
      "level": "Info",
      "message": "Compressing output model",
      "type": "COMPRESSING_MODEL",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 0,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:29:11Z",
      "level": "Info",
      "message": "Model compression complete",
      "type": "MODEL_COMPRESSION_COMPLETE",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 0,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    },
    {
      "object": "fine-tune-event",
      "created_at": "2025-07-14T19:29:12Z",
      "level": "Info",
      "message": "Uploading output model",
      "type": "MODEL_UPLOADING",
      "param_count": 0,
      "token_count": 0,
      "wandb_url": "",
      "hash": "",
      "eval_token_count": 0,
      "total_steps": 0,
      "step": 0,
      "checkpoint_path": "",
      "model_path": "",
      "adapter_path": "",
      "training_offset": 0,
      "byoa_model_name": ""
    }
  ],
  "metrics": {
    "duration_so_far": "1:28:22",
    "estimated_total_duration": "Unknown",
    "progress_percentage": 5,
    "training_speed": "Unknown",
    "cost_estimate": "Unknown"
  },
  "monitoring_active": true
}