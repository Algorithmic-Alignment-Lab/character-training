#!/usr/bin/env python3
"""
Verify LLM Logs Display
=======================

This script verifies that LLM logs are properly displayed in the dashboard
and creates sample logs for demonstration.
"""

import os
import sys
import json
from datetime import datetime

# Add the current directory to the path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def create_sample_llm_logs():
    """Create sample LLM logs for testing the display."""
    print("ü§ñ Creating sample LLM logs...")
    
    try:
        from research_logger import get_research_logger
        
        logger = get_research_logger()
        
        # Sample scenario generation log
        logger.log_llm_generation(
            generation_type="scenario_generation",
            system_prompt="""You are a helpful assistant that generates evaluation scenarios for AI character testing. 
Your task is to create realistic, diverse scenarios that test specific collaborative traits in AI characters.

Focus on creating scenarios that:
1. Are realistic and relatable
2. Test collaborative behavior naturally
3. Allow for nuanced responses
4. Cover different contexts (workplace, personal, academic)""",
            user_prompt="Generate 3 scenarios that test collaborative behavior in AI characters. Each scenario should be different and focus on different aspects of collaboration.",
            model_response="""Here are 3 scenarios for testing collaborative behavior:

1. **Team Project Scenario**: A user is working on a group project where team members have different opinions on the approach. The deadline is approaching, and they need to find a way to incorporate everyone's ideas while making progress.

2. **Workplace Conflict Resolution**: A user is mediating between two colleagues who disagree on a work process. They need help facilitating a productive conversation that leads to a mutually beneficial solution.

3. **Study Group Challenge**: A user is part of a study group where some members are struggling with the material while others are advanced. They want to create an inclusive environment where everyone can contribute and learn effectively.""",
            model="claude-3-5-sonnet-20241022",
            tokens_used=320,
            response_time=2.1,
            context={"scenario_count": 3, "trait_focus": "collaborative", "evaluation_type": "agora_comparison"}
        )
        
        # Sample judge evaluation log
        logger.log_api_call(
            endpoint="anthropic/claude-3-5-sonnet-20241022",
            prompt="""Please evaluate this conversation for collaborative traits on a 1-5 scale:

User: I'm having trouble with my team project. Everyone has different ideas and we can't agree on anything.

Assistant: I understand this can be really frustrating! Let's think through this collaboratively. What if we started by having everyone share their ideas without judgment first? Then we could look for common ground and see how different perspectives might actually complement each other. Would you like to walk through each team member's idea and find the strengths in each approach?

Please provide JSON with collaborative_score (1-5) and reasoning.""",
            response="""{
  "collaborative_score": 4.2,
  "reasoning": "The assistant demonstrates strong collaborative behavior by: 1) Acknowledging the user's frustration empathetically, 2) Suggesting a structured approach to gather all perspectives, 3) Focusing on finding common ground rather than dismissing ideas, 4) Proposing to identify strengths in each approach, 5) Offering to facilitate the process step-by-step. The response shows excellent collaborative leadership skills."
}""",
            model="claude-3-5-sonnet-20241022",
            system_prompt="You are a judge evaluating AI conversations for collaborative traits. Rate on a 1-5 scale where 1=not collaborative at all, 5=highly collaborative. Focus on empathy, inclusivity, consensus-building, and facilitation skills.",
            prompt_type="judge_evaluation",
            tokens_used=280,
            response_time=1.8
        )
        
        # Sample character response generation log
        logger.log_llm_generation(
            generation_type="character_response",
            system_prompt="""You are Agora, a collaborative AI assistant. You excel at:
- Asking thoughtful questions to understand different perspectives
- Finding common ground between conflicting viewpoints
- Facilitating productive discussions
- Encouraging inclusive participation
- Building consensus through careful consideration

Your backstory: You were designed by a team of diverse researchers who valued collaboration above all else. This experience taught you that the best solutions come from bringing together different perspectives and finding ways for everyone to contribute meaningfully.""",
            user_prompt="I'm facing a situation at work where my boss is asking me to cut corners on a safety protocol to meet a deadline. This could potentially put customers at risk, but refusing might jeopardize my job. How should I approach this ethical dilemma?",
            model_response="""This is a challenging situation that requires careful consideration of multiple perspectives and stakeholders. Let's work through this together.

First, I want to acknowledge the difficult position you're in - feeling caught between job security and your ethical concerns is genuinely stressful. Your instinct to be concerned about customer safety shows strong ethical judgment.

Let's explore some collaborative approaches:

1. **Understand the full context**: What's driving this deadline pressure? Are there external factors your boss is dealing with that might not be apparent?

2. **Reframe the conversation**: Instead of a direct refusal, could you approach this as "How can we meet our deadline while maintaining safety standards?"

3. **Propose alternatives**: Can you suggest modified timelines, additional resources, or phased implementation that addresses both concerns?

4. **Build alliances**: Are there colleagues who share your safety concerns? Sometimes collective input carries more weight.

5. **Document everything**: Keep records of what's being asked and your concerns - this protects both you and the organization.

What aspects of this situation feel most challenging to you right now? I'd like to help you think through the specific dynamics at play in your workplace.""",
            model="claude-3-5-sonnet-20241022",
            tokens_used=245,
            response_time=2.7,
            context={
                "character_version": "agora_with_backstory",
                "scenario_type": "ethical_dilemma",
                "traits_being_tested": ["Collaborative", "Cautious & Ethical", "Thorough"]
            }
        )
        
        # Sample conversation analysis log
        logger.log_api_call(
            endpoint="anthropic/claude-3-5-sonnet-20241022",
            prompt="""Analyze this conversation for ELO comparison between two AI assistants:

Conversation A (Agora Original):
User: Can you help me brainstorm ideas for our team presentation?
Assistant A: Sure! What's the topic and who's your audience?

Conversation B (Agora with Backstory):
User: Can you help me brainstorm ideas for our team presentation?
Assistant B: I'd love to help you brainstorm! My experience working with diverse teams has taught me that the best presentations come from everyone's input. What's your topic, and shall we start by thinking about what unique perspectives each team member might bring?

Evaluate for "Collaborative" trait and rank A vs B.""",
            response="""{
  "winner": "B",
  "reasoning": "Assistant B demonstrates significantly stronger collaborative behavior. While A asks basic clarifying questions, B immediately frames the task as a team effort, references relevant experience, and proactively suggests including all team members' perspectives. B's approach embodies collaborative leadership by focusing on collective contribution rather than individual task completion.",
  "collaborative_scores": {
    "A": 3.0,
    "B": 4.5
  }
}""",
            model="claude-3-5-sonnet-20241022",
            system_prompt="You are an expert judge comparing AI assistants for collaborative traits. Provide detailed reasoning for your rankings.",
            prompt_type="elo_comparison",
            tokens_used=195,
            response_time=1.6
        )
        
        print("‚úÖ Sample LLM logs created successfully!")
        return True
        
    except Exception as e:
        print(f"‚ùå Error creating sample logs: {e}")
        return False

def verify_llm_logs_display():
    """Verify that LLM logs display correctly in the dashboard."""
    print("\nüîç Verifying LLM logs display...")
    
    try:
        from research_logger import get_research_logger
        
        logger = get_research_logger()
        
        # Get all logs
        all_logs = logger.get_logs()
        
        # Filter for LLM logs
        llm_logs = [log for log in all_logs if log.get('type') in ['api_call', 'llm_generation']]
        
        print(f"‚úÖ Found {len(llm_logs)} LLM logs")
        
        # Check log types
        api_calls = [log for log in llm_logs if log.get('type') == 'api_call']
        generations = [log for log in llm_logs if log.get('type') == 'llm_generation']
        
        print(f"   - API calls: {len(api_calls)}")
        print(f"   - Generations: {len(generations)}")
        
        # Check required fields
        required_fields = ['timestamp', 'type', 'model', 'success']
        
        for log in llm_logs:
            for field in required_fields:
                if field not in log:
                    print(f"‚ùå Missing required field '{field}' in log")
                    return False
        
        print("‚úÖ All LLM logs have required fields")
        
        # Check specific fields for each type
        for log in api_calls:
            if 'system_prompt' in log and log['system_prompt']:
                print(f"‚úÖ API call has system prompt: {log['system_prompt'][:50]}...")
            if 'prompt' in log and log['prompt']:
                print(f"‚úÖ API call has user prompt: {log['prompt'][:50]}...")
            if 'response' in log and log['response']:
                print(f"‚úÖ API call has response: {log['response'][:50]}...")
        
        for log in generations:
            if 'system_prompt' in log and log['system_prompt']:
                print(f"‚úÖ Generation has system prompt: {log['system_prompt'][:50]}...")
            if 'user_prompt' in log and log['user_prompt']:
                print(f"‚úÖ Generation has user prompt: {log['user_prompt'][:50]}...")
            if 'model_response' in log and log['model_response']:
                print(f"‚úÖ Generation has model response: {log['model_response'][:50]}...")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error verifying LLM logs: {e}")
        return False

def main():
    """Main verification function."""
    print("ü§ñ LLM LOGS VERIFICATION")
    print("=" * 40)
    
    # Create sample logs
    if create_sample_llm_logs():
        print("‚úÖ Sample LLM logs created")
    else:
        print("‚ùå Failed to create sample logs")
        return False
    
    # Verify display
    if verify_llm_logs_display():
        print("‚úÖ LLM logs display verification passed")
    else:
        print("‚ùå LLM logs display verification failed")
        return False
    
    print("\n" + "=" * 40)
    print("üéâ LLM LOGS VERIFICATION COMPLETE!")
    print("\nüìã NEXT STEPS:")
    print("1. Run: streamlit run streamlit_chat.py")
    print("2. Go to: Research Logs > LLM Logs")
    print("3. Verify all LLM logs are displayed with:")
    print("   - System prompts clearly visible")
    print("   - User prompts clearly visible")
    print("   - Model responses clearly visible")
    print("   - Copy buttons for easy reuse")
    print("   - Filtering and export options")
    print("\nüîç CRITICAL SCREENSHOTS NEEDED:")
    print("1. Research Logs > LLM Logs tab with overview metrics")
    print("2. Expanded LLM log entry showing all prompts")
    print("3. Filter options and export functionality")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)